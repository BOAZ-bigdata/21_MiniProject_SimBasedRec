{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44735,"status":"ok","timestamp":1692288932062,"user":{"displayName":"신유라","userId":"03768500327706671193"},"user_tz":-540},"id":"BFttDdsW2JjT","outputId":"ffd2a037-b224-4926-90c2-9382bbb9ac71"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: mxnet in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (1.7.0.post2)\n","Requirement already satisfied: numpy<2.0.0,>1.16.0 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from mxnet) (1.23.1)\n","Requirement already satisfied: requests<3,>=2.20.0 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from mxnet) (2.29.0)\n","Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from mxnet) (0.8.4)\n","Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet) (3.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet) (3.1.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet) (2023.5.7)\n","Requirement already satisfied: gluonnlp==0.8.0 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (0.8.0)\n","Requirement already satisfied: numpy in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from gluonnlp==0.8.0) (1.23.1)\n","Requirement already satisfied: pandas in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (1.3.0)\n","Requirement already satisfied: tqdm in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (4.63.1)\n","Requirement already satisfied: numpy>=1.17.3 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from pandas) (1.23.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from pandas) (2023.3)\n","Requirement already satisfied: six>=1.5 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n","Requirement already satisfied: sentencepiece in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (0.1.96)\n","Requirement already satisfied: transformers in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (4.29.2)\n","Requirement already satisfied: packaging>=20.0 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from transformers) (23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from transformers) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from transformers) (0.13.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from transformers) (0.14.1)\n","Requirement already satisfied: numpy>=1.17 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from transformers) (1.23.1)\n","Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from transformers) (2023.3.23)\n","Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from transformers) (4.63.1)\n","Requirement already satisfied: requests in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from transformers) (2.29.0)\n","Requirement already satisfied: filelock in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from transformers) (3.10.7)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: fsspec in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from requests->transformers) (3.1.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from requests->transformers) (1.26.16)\n","Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from requests->transformers) (2023.5.7)\n","Requirement already satisfied: torch in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (2.0.1)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from torch) (11.7.99)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from torch) (8.5.0.96)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from torch) (10.2.10.91)\n","Requirement already satisfied: networkx in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from torch) (3.0)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from torch) (11.4.0.1)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from torch) (2.14.3)\n","Requirement already satisfied: jinja2 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from torch) (2.0.0)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from torch) (11.7.101)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from torch) (11.7.99)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from torch) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from torch) (10.9.0.58)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from torch) (11.7.91)\n","Requirement already satisfied: typing-extensions in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from torch) (4.5.0)\n","Requirement already satisfied: filelock in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from torch) (3.10.7)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from torch) (11.7.4.91)\n","Requirement already satisfied: sympy in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from torch) (1.11.1)\n","Requirement already satisfied: setuptools in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (59.5.0)\n","Requirement already satisfied: wheel in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n","Requirement already satisfied: cmake in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from triton==2.0.0->torch) (3.26.1)\n","Requirement already satisfied: lit in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from triton==2.0.0->torch) (16.0.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from jinja2->torch) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n"]}],"source":["!pip install mxnet\n","!pip install gluonnlp==0.8.0\n","!pip install pandas tqdm\n","!pip install sentencepiece\n","!pip install transformers\n","!pip install torch"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7910,"status":"ok","timestamp":1692288939970,"user":{"displayName":"신유라","userId":"03768500327706671193"},"user_tz":-540},"id":"IyluPO3n2NJN","outputId":"3a5722fd-3f2c-4f67-c0f8-73a232b49a58"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting kobert_tokenizer\n","  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-pzgxsaq5/kobert-tokenizer_4125ca041593441a93482099a80337a8\n","  Running command git clone --filter=blob:none --quiet https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-pzgxsaq5/kobert-tokenizer_4125ca041593441a93482099a80337a8\n","  Resolved https://github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25h"]}],"source":["!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2639,"status":"ok","timestamp":1692288942607,"user":{"displayName":"신유라","userId":"03768500327706671193"},"user_tz":-540},"id":"fVuPlSJb2Nbk","outputId":"42e4da5a-302d-4204-851f-60cbdd4d08ec"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages/mxnet/optimizer/optimizer.py:163: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\n","  warnings.warn('WARNING: New optimizer %s.%s is overriding '\n"]}],"source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import gluonnlp as nlp\n","import numpy as np\n","from tqdm import tqdm, tqdm_notebook"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5551,"status":"ok","timestamp":1692288948147,"user":{"displayName":"신유라","userId":"03768500327706671193"},"user_tz":-540},"id":"32gHMEjz2Nn0"},"outputs":[],"source":["# ★ Hugging Face를 통한 모델 및 토크나이저 Import\n","from kobert_tokenizer import KoBERTTokenizer\n","from transformers import BertModel\n","\n","from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1692288948148,"user":{"displayName":"신유라","userId":"03768500327706671193"},"user_tz":-540},"id":"32RBZXPx2Nzp"},"outputs":[],"source":["# GPU 사용 시\n","device = torch.device(\"cuda:0\")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1002,"status":"ok","timestamp":1692288949133,"user":{"displayName":"신유라","userId":"03768500327706671193"},"user_tz":-540},"id":"jw-qNx5L2N_6","outputId":"6cad22e3-d73c-4562-c73a-9733228be2a9"},"outputs":[{"name":"stderr","output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n","The class this function is called from is 'KoBERTTokenizer'.\n"]}],"source":["# ★\n","tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n","bertmodel = BertModel.from_pretrained('skt/kobert-base-v1', return_dict=False)\n","vocab = nlp.vocab.BERTVocab.from_sentencepiece(tokenizer.vocab_file, padding_token='[PAD]')"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1692288949134,"user":{"displayName":"신유라","userId":"03768500327706671193"},"user_tz":-540},"id":"6WxvYhQaw3cE"},"outputs":[],"source":["import pandas as pd\n","\n","data = pd.read_csv('concat.csv')"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":1357,"status":"ok","timestamp":1692288950489,"user":{"displayName":"신유라","userId":"03768500327706671193"},"user_tz":-540},"id":"eiasHSvXP_UH","outputId":"62377424-908a-49c0-ee9f-f958b947674e"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word_2</th>\n","      <th>facts</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>83</td>\n","      <td>「공모관계」 전화금융사기는 불특정 다수의 사람에게 전화를 걸어 검찰, 경찰 등 수사...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>94</td>\n","      <td>『2019고단5912』 1. 피고인은 2019. 7. 14.경 부산 연제구 F건물 ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>83</td>\n","      <td>피고인은 2020. 8. 중순경 ‘간단한 출장업무 일 30~50만 원 직원 모집합니...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>94</td>\n","      <td>[범죄전력] 피고인은 2019. 5. 9. 부산지방법원에서 사기죄 등으로 징역 1년...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>94</td>\n","      <td>【범죄전력】 피고인은 2021. 6. 9. 서울서부지방법원에서 사기죄 등으로 징역 ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>17236</th>\n","      <td>96</td>\n","      <td>피해자 B은 평택시 C에 있는 D를 운영하는 자이고, 피고인은 위 회사의 화물기사이...</td>\n","    </tr>\n","    <tr>\n","      <th>17237</th>\n","      <td>96</td>\n","      <td>【범죄전력】 피고인은 2019. 7. 19. 의정부지방법원에서 사기죄로 징역 10월...</td>\n","    </tr>\n","    <tr>\n","      <th>17238</th>\n","      <td>96</td>\n","      <td>피고인은 피해자 B의 외조카로서 피해자 소유의 고양시 일산동구 C 소재 다가구주택 ...</td>\n","    </tr>\n","    <tr>\n","      <th>17239</th>\n","      <td>96</td>\n","      <td>[범죄전력] 피고인은 2021. 4. 22. 인천지방법원에서 컴퓨터등사용사기죄 등으...</td>\n","    </tr>\n","    <tr>\n","      <th>17240</th>\n","      <td>96</td>\n","      <td>피고인은 2019. 6. 2. 피해자 B에게 검정색 푸들 1마리를 분양한 뒤, 20...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>17241 rows × 2 columns</p>\n","</div>"],"text/plain":["       word_2                                              facts\n","0          83  「공모관계」 전화금융사기는 불특정 다수의 사람에게 전화를 걸어 검찰, 경찰 등 수사...\n","1          94  『2019고단5912』 1. 피고인은 2019. 7. 14.경 부산 연제구 F건물 ...\n","2          83  피고인은 2020. 8. 중순경 ‘간단한 출장업무 일 30~50만 원 직원 모집합니...\n","3          94  [범죄전력] 피고인은 2019. 5. 9. 부산지방법원에서 사기죄 등으로 징역 1년...\n","4          94  【범죄전력】 피고인은 2021. 6. 9. 서울서부지방법원에서 사기죄 등으로 징역 ...\n","...       ...                                                ...\n","17236      96  피해자 B은 평택시 C에 있는 D를 운영하는 자이고, 피고인은 위 회사의 화물기사이...\n","17237      96  【범죄전력】 피고인은 2019. 7. 19. 의정부지방법원에서 사기죄로 징역 10월...\n","17238      96  피고인은 피해자 B의 외조카로서 피해자 소유의 고양시 일산동구 C 소재 다가구주택 ...\n","17239      96  [범죄전력] 피고인은 2021. 4. 22. 인천지방법원에서 컴퓨터등사용사기죄 등으...\n","17240      96  피고인은 2019. 6. 2. 피해자 B에게 검정색 푸들 1마리를 분양한 뒤, 20...\n","\n","[17241 rows x 2 columns]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","\n","data_df = pd.DataFrame(data)\n","\n","# 라벨 인코딩을 위한 LabelEncoder 생성\n","label_encoder = LabelEncoder()\n","\n","# 특정 열에 대해 라벨 인코딩 적용\n","data_df['word_2'] = label_encoder.fit_transform(data_df['word_1'])\n","\n","data_df = data_df[['word_2', 'facts']]\n","data_df"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","train_ratio = 0.7\n","validation_ratio = 0.15\n","test_ratio = 0.15\n","\n","train_df, temp = train_test_split(data_df, test_size=1 - train_ratio)\n","valid_df, test_df = train_test_split(temp, test_size=test_ratio / (test_ratio + validation_ratio), random_state=0)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1692288950490,"user":{"displayName":"신유라","userId":"03768500327706671193"},"user_tz":-540},"id":"sp0KH4h_IACC"},"outputs":[],"source":["train_data_list = []\n","for q, label in zip(train_df['facts'], train_df['word_2'])  :\n","    data = []\n","    data.append(q)\n","    data.append(str(label))\n","\n","    train_data_list.append(data)\n","\n","dataset_train = train_data_list"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["valid_data_list = []\n","for q, label in zip(valid_df['facts'], valid_df['word_2'])  :\n","    data = []\n","    data.append(q)\n","    data.append(str(label))\n","\n","    valid_data_list.append(data)\n","\n","dataset_valid = valid_data_list"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["test_data_list = []\n","for q, label in zip(test_df['facts'], test_df['word_2'])  :\n","    data = []\n","    data.append(q)\n","    data.append(str(label))\n","\n","    test_data_list.append(data)\n","\n","dataset_test = test_data_list"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1692288950490,"user":{"displayName":"신유라","userId":"03768500327706671193"},"user_tz":-540},"id":"ykhrVgg1xUWl"},"outputs":[],"source":["class BERTDataset(Dataset):\n","    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, vocab, max_len,\n","                 pad, pair):\n","        transform = BERTSentenceTransform(bert_tokenizer, max_seq_length=max_len,vocab=vocab, pad=pad, pair=pair)\n","        #transform = nlp.data.BERTSentenceTransform(\n","        #    tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n","        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n","        self.labels = [np.int32(i[label_idx]) for i in dataset]\n","\n","    def __getitem__(self, i):\n","        return (self.sentences[i] + (self.labels[i], ))\n","\n","    def __len__(self):\n","        return (len(self.labels))"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1692288950490,"user":{"displayName":"신유라","userId":"03768500327706671193"},"user_tz":-540},"id":"KtipEuEfmEk9"},"outputs":[],"source":["class BERTSentenceTransform:\n","    r\"\"\"BERT style data transformation.\n","\n","    Parameters\n","    ----------\n","    tokenizer : BERTTokenizer.\n","        Tokenizer for the sentences.\n","    max_seq_length : int.\n","        Maximum sequence length of the sentences.\n","    vocab : Vocab\n","        The vocabulary which has cls_token and sep_token registered.\n","        If vocab.cls_token is not present, vocab.bos_token is used instead.\n","        If vocab.sep_token is not present, vocab.eos_token is used instead.\n","    pad : bool, default True\n","        Whether to pad the sentences to maximum length.\n","    pair : bool, default True\n","        Whether to transform sentences or sentence pairs.\n","    \"\"\"\n","\n","    def __init__(self, tokenizer, max_seq_length, vocab=None, pad=True, pair=True):\n","        self._tokenizer = tokenizer\n","        self._max_seq_length = max_seq_length\n","        self._pad = pad\n","        self._pair = pair\n","        self._vocab = self._tokenizer.vocab if vocab is None else vocab\n","        # RoBERTa does not register CLS token and SEP token\n","        if hasattr(self._vocab, 'cls_token'):\n","            self._cls_token = self._vocab.cls_token\n","        else:\n","            self._cls_token = self._vocab.bos_token\n","        if hasattr(self._vocab, 'sep_token'):\n","            self._sep_token = self._vocab.sep_token\n","        else:\n","            self._sep_token = self._vocab.eos_token\n","        self._padding_token = self._vocab.padding_token\n","\n","    def __call__(self, line):\n","        \"\"\"Perform transformation for sequence pairs or single sequences.\n","\n","        The transformation is processed in the following steps:\n","        - tokenize the input sequences\n","        - insert [CLS], [SEP] as necessary\n","        - generate type ids to indicate whether a token belongs to the first\n","        sequence or the second sequence.\n","        - generate valid length\n","\n","        For sequence pairs, the input is a tuple of 2 strings:\n","        text_a, text_b.\n","\n","        Inputs:\n","            text_a: 'is this jacksonville ?'\n","            text_b: 'no it is not'\n","        Tokenization:\n","            text_a: 'is this jack ##son ##ville ?'\n","            text_b: 'no it is not .'\n","        Processed:\n","            tokens: '[CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]'\n","            type_ids: 0     0  0    0    0     0       0 0     1  1  1  1   1 1\n","            valid_length: 14\n","\n","        For single sequences, the input is a tuple of single string:\n","        text_a.\n","\n","        Inputs:\n","            text_a: 'the dog is hairy .'\n","        Tokenization:\n","            text_a: 'the dog is hairy .'\n","        Processed:\n","            text_a: '[CLS] the dog is hairy . [SEP]'\n","            type_ids: 0     0   0   0  0     0 0\n","            valid_length: 7\n","\n","        If vocab.cls_token and vocab.sep_token are not present,\n","        vocab.bos_token and vocab.eos_token are used instead.\n","\n","        Parameters\n","        ----------\n","        line: tuple of str\n","            Input strings. For sequence pairs, the input is a tuple of 2 strings:\n","            (text_a, text_b). For single sequences, the input is a tuple of single\n","            string: (text_a,).\n","\n","        Returns\n","        -------\n","        np.array: input token ids in 'int32', shape (batch_size, seq_length)\n","        np.array: valid length in 'int32', shape (batch_size,)\n","        np.array: input token type ids in 'int32', shape (batch_size, seq_length)\n","\n","        \"\"\"\n","\n","        # convert to unicode\n","        text_a = line[0]\n","        if self._pair:\n","            assert len(line) == 2\n","            text_b = line[1]\n","\n","        tokens_a = self._tokenizer.tokenize(text_a)\n","        tokens_b = None\n","\n","        if self._pair:\n","            tokens_b = self._tokenizer.tokenize(text_b)\n","\n","        if tokens_b:\n","            # Modifies `tokens_a` and `tokens_b` in place so that the total\n","            # length is less than the specified length.\n","            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n","            self._truncate_seq_pair(tokens_a, tokens_b,\n","                                    self._max_seq_length - 3)\n","        else:\n","            # Account for [CLS] and [SEP] with \"- 2\"\n","            if len(tokens_a) > self._max_seq_length - 2:\n","                tokens_a = tokens_a[0:(self._max_seq_length - 2)]\n","\n","        # The embedding vectors for `type=0` and `type=1` were learned during\n","        # pre-training and are added to the wordpiece embedding vector\n","        # (and position vector). This is not *strictly* necessary since\n","        # the [SEP] token unambiguously separates the sequences, but it makes\n","        # it easier for the model to learn the concept of sequences.\n","\n","        # For classification tasks, the first vector (corresponding to [CLS]) is\n","        # used as as the \"sentence vector\". Note that this only makes sense because\n","        # the entire model is fine-tuned.\n","        tokens = []\n","        tokens.append(self._cls_token)\n","        tokens.extend(tokens_a)\n","        tokens.append(self._sep_token)\n","        segment_ids = [0] * len(tokens)\n","\n","        if tokens_b:\n","            tokens.extend(tokens_b)\n","            tokens.append(self._sep_token)\n","            segment_ids.extend([1] * (len(tokens) - len(segment_ids)))\n","\n","        input_ids = self._vocab[tokens]\n","\n","        # The valid length of sentences. Only real  tokens are attended to.\n","        valid_length = len(input_ids)\n","\n","        if self._pad:\n","            # Zero-pad up to the sequence length.\n","            padding_length = self._max_seq_length - valid_length\n","            # use padding tokens for the rest\n","            input_ids.extend([self._vocab[self._padding_token]] * padding_length)\n","            segment_ids.extend([0] * padding_length)\n","\n","        return np.array(input_ids, dtype='int32'), np.array(valid_length, dtype='int32'), np.array(segment_ids, dtype='int32')\n","\n","\n","    def _truncate_seq_pair(self, tokens_a, tokens_b, max_length):\n","        \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n","        # This is a simple heuristic which will always truncate the longer sequence\n","        # one token at a time. This makes more sense than truncating an equal percent\n","        # of tokens from each, since if one sequence is very short then each token\n","        # that's truncated likely contains more information than a longer sequence.\n","        while True:\n","            total_length = len(tokens_a) + len(tokens_b)\n","            if total_length <= max_length:\n","                break\n","            if len(tokens_a) > len(tokens_b):\n","                tokens_a.pop()\n","            else:\n","                tokens_b.pop()\n"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1692288950490,"user":{"displayName":"신유라","userId":"03768500327706671193"},"user_tz":-540},"id":"kisDxWGmIAIX"},"outputs":[],"source":["# Setting parameters\n","max_len = 64\n","batch_size = 64\n","warmup_ratio = 0.1\n","num_epochs = 4\n","max_grad_norm = 1\n","log_interval = 200\n","learning_rate =  5e-5"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":43541,"status":"ok","timestamp":1692288994025,"user":{"displayName":"신유라","userId":"03768500327706671193"},"user_tz":-540},"id":"4rkR4zFXINjB"},"outputs":[],"source":["#토큰화\n","tok = tokenizer.tokenize\n","\n","data_train = BERTDataset(dataset_train, 0, 1, tokenizer, vocab, max_len, True, False)\n","data_valid = BERTDataset(dataset_valid, 0, 1, tokenizer, vocab, max_len, True, False)\n","data_test = BERTDataset(dataset_test, 0, 1, tokenizer, vocab, max_len, True, False)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1692288994025,"user":{"displayName":"신유라","userId":"03768500327706671193"},"user_tz":-540},"id":"rlJXj4HoINnM","outputId":"c9ce9e6c-ae2a-4905-c197-121f78a63fe8"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n","valid_dataloader = torch.utils.data.DataLoader(data_valid, batch_size=batch_size, num_workers=5)\n","test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1692288994025,"user":{"displayName":"신유라","userId":"03768500327706671193"},"user_tz":-540},"id":"L6wUE1I3INpJ"},"outputs":[],"source":["class BERTClassifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_size = 768,\n","                 num_classes=99,   ##클래스 수 조정##\n","                 dr_rate=None,\n","                 params=None):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","\n","        self.classifier = nn.Linear(hidden_size , num_classes)\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p=dr_rate)\n","\n","    def gen_attention_mask(self, token_ids, valid_length):\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","\n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        return self.classifier(out)\n"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1692288994025,"user":{"displayName":"신유라","userId":"03768500327706671193"},"user_tz":-540},"id":"sgn0WgqDINrW","outputId":"6dc8d5cb-91c0-4dc5-8cf8-2eee2c531733"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ubuntu/kie/anaconda3/envs/etri/lib/python3.8/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"data":{"text/plain":["<torch.utils.data.dataloader.DataLoader at 0x7f026c8a1160>"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n","\n","# Prepare optimizer and schedule (linear warmup and decay)\n","no_decay = ['bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]\n","\n","optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","t_total = len(train_dataloader) * num_epochs\n","warmup_step = int(t_total * warmup_ratio)\n","\n","scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n","\n","def calc_accuracy(X,Y):\n","    max_vals, max_indices = torch.max(X, 1)\n","    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n","    return train_acc\n","\n","train_dataloader"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":539,"referenced_widgets":["17abbf90314645a2b37255c6d8766105","75f5b637d77d4ba6af70ee3717a2814c","086f5ed47ba94c0eadc86210ac8e3260","a38cdf33185f41d08aee3083173fb6f0","a116a4c0aa0244feba3e06de6f0d85a7","6bc5f3b7a6fe4424aacb748ce289a166","e50de81ddb4741c59aec1629e9a1ddc6","84409f35a2384f759f0097e1c7ad76c7","87d3246e6da9417ab3b77820175c1999","1e195d2449294b4e89434797e1719f0f","784cde4c71584ea78a97b6497e15c672"]},"executionInfo":{"elapsed":129140,"status":"error","timestamp":1692289123149,"user":{"displayName":"신유라","userId":"03768500327706671193"},"user_tz":-540},"id":"cZmNeVUoINte","outputId":"54b2d9ea-0960-4075-b367-9dde35df1806"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_2338/3383866892.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n"]},{"data":{"application/json":{"ascii":false,"bar_format":null,"colour":null,"elapsed":0.004835367202758789,"initial":0,"n":0,"ncols":null,"nrows":null,"postfix":null,"prefix":"","rate":null,"total":189,"unit":"it","unit_divisor":1000,"unit_scale":false},"application/vnd.jupyter.widget-view+json":{"model_id":"c6f3a63fed7c4c8cbc589f4f6ba1a14f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/189 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch 1 batch id 1 loss 4.696157932281494 train acc 0.015625\n","epoch 1 train acc 0.3425374779541446\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_2338/3383866892.py:23: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(valid_dataloader)):\n"]},{"data":{"application/json":{"ascii":false,"bar_format":null,"colour":null,"elapsed":0.0048482418060302734,"initial":0,"n":0,"ncols":null,"nrows":null,"postfix":null,"prefix":"","rate":null,"total":41,"unit":"it","unit_divisor":1000,"unit_scale":false},"application/vnd.jupyter.widget-view+json":{"model_id":"385fe41689af4aa990e89c3d9b08920e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/41 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch 1 valid acc 0.5110225140712945\n"]},{"data":{"application/json":{"ascii":false,"bar_format":null,"colour":null,"elapsed":0.004760026931762695,"initial":0,"n":0,"ncols":null,"nrows":null,"postfix":null,"prefix":"","rate":null,"total":189,"unit":"it","unit_divisor":1000,"unit_scale":false},"application/vnd.jupyter.widget-view+json":{"model_id":"d931566fae224ea488d230a3a81628f2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/189 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch 2 batch id 1 loss 2.221365213394165 train acc 0.46875\n","epoch 2 train acc 0.5611496913580247\n"]},{"data":{"application/json":{"ascii":false,"bar_format":null,"colour":null,"elapsed":0.004832267761230469,"initial":0,"n":0,"ncols":null,"nrows":null,"postfix":null,"prefix":"","rate":null,"total":41,"unit":"it","unit_divisor":1000,"unit_scale":false},"application/vnd.jupyter.widget-view+json":{"model_id":"0f313268fc1a4027a94f71fb7b7b61bc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/41 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch 2 valid acc 0.6011374296435272\n"]},{"data":{"application/json":{"ascii":false,"bar_format":null,"colour":null,"elapsed":0.0049436092376708984,"initial":0,"n":0,"ncols":null,"nrows":null,"postfix":null,"prefix":"","rate":null,"total":189,"unit":"it","unit_divisor":1000,"unit_scale":false},"application/vnd.jupyter.widget-view+json":{"model_id":"c502970d2b89494d865e68b2a5a71c92","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/189 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch 3 batch id 1 loss 1.6225935220718384 train acc 0.65625\n","epoch 3 train acc 0.6327895355673134\n"]},{"data":{"application/json":{"ascii":false,"bar_format":null,"colour":null,"elapsed":0.0047724246978759766,"initial":0,"n":0,"ncols":null,"nrows":null,"postfix":null,"prefix":"","rate":null,"total":41,"unit":"it","unit_divisor":1000,"unit_scale":false},"application/vnd.jupyter.widget-view+json":{"model_id":"5d811dd46e6c4ec4a53098c2f0b83c9d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/41 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["epoch 3 valid acc 0.6112511726078799\n"]}],"source":["for e in range(num_epochs):\n","    train_acc = 0.0\n","    valid_acc = 0.0\n","    model.train()\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n","        optimizer.zero_grad()\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","        out = model(token_ids, valid_length, segment_ids)\n","        loss = loss_fn(out, label)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","        optimizer.step()\n","        scheduler.step()  # Update learning rate schedule\n","        train_acc += calc_accuracy(out, label)\n","        if batch_id % log_interval == 0:\n","            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n","    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n","\n","    model.eval()\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(valid_dataloader)):\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","        out = model(token_ids, valid_length, segment_ids)\n","        valid_acc += calc_accuracy(out, label)\n","    print(\"epoch {} valid acc {}\".format(e+1, valid_acc / (batch_id+1)))"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1692289123150,"user":{"displayName":"신유라","userId":"03768500327706671193"},"user_tz":-540},"id":"1WTMIBjV_avs"},"outputs":[],"source":["torch.save(model, 'model.pt')"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_2338/1226072847.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n"]},{"data":{"application/json":{"ascii":false,"bar_format":null,"colour":null,"elapsed":0.0049228668212890625,"initial":0,"n":0,"ncols":null,"nrows":null,"postfix":null,"prefix":"","rate":null,"total":41,"unit":"it","unit_divisor":1000,"unit_scale":false},"application/vnd.jupyter.widget-view+json":{"model_id":"1fce8ebc65f54ca698b28a5c968d9e67","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/41 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Accuracy: 0.6168699186991871\n"]}],"source":["test_acc = 0\n","model.eval()\n","for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n","    token_ids = token_ids.long().to(device)\n","    segment_ids = segment_ids.long().to(device)\n","    valid_length= valid_length\n","    label = label.long().to(device)\n","    out = model(token_ids, valid_length, segment_ids)\n","    test_acc += calc_accuracy(out, label)\n","print(\"Accuracy:\", test_acc / (batch_id+1))"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy Score: 0.6666666666666666\n","F1 Score: 0.45895691609977324\n"]}],"source":["from sklearn.metrics import f1_score, accuracy_score\n","\n","label = label.cpu().detach()\n","max_vals, max_indices = torch.max(out, 1)\n","max_indices = max_indices.cpu().detach()\n","\n","accuracy = accuracy_score(label, max_indices)\n","\n","f1 = f1_score(label, max_indices, average='macro')\n","\n","print(\"Accuracy Score:\", accuracy)\n","print(\"F1 Score:\", f1)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["def predict(predict_sentence):\n","\n","    data = [predict_sentence, '0']\n","    dataset_another = [data]\n","\n","    another_test = BERTDataset(dataset_another, 0, 1, tokenizer, vocab, max_len, True, False)\n","    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n","    \n","    model.eval()\n","\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","\n","        out = model(token_ids, valid_length, segment_ids)\n","\n","        for i in out:\n","            logits=i\n","            logits = logits.detach().cpu().numpy()\n","            answer = np.argmax(logits)\n","\n","    return answer"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["피고인은 2021. 4. 21. 수원고등법원에서 업무방해, 특수협박 등 죄로 징역 2년을 선고받아 2021. 5. 7. 위 판결이 확정되었다. 피고인은 2020. 4. 11. 01:30경 여주시 B에 있는 피해자 C(남, 3*세)이 운영하는 ‘D 노래방’ 3번방에서, “나는 무고한 사람이니까 C은 무고한 사람을 신고해서 돈을 버는 놈이고 E F보다 개새끼다.”, “씨발, 좆팔, 개새끼, 씹새끼.”라고 큰 소리로 욕설을 하고, 맥주병을 집어던지는 등 소란을 피워 위력으로써 피해자의 유흥주점 영업 업무를 방해하였다.\n","형법 제314조\n"]}],"source":["sentence = dataset_test[4][0]\n","encoded_label = predict(sentence)\n","decoded_label = label_encoder.inverse_transform([encoded_label])[0]\n","print(sentence)\n","print(decoded_label)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOCllu83sCf3Cgkfwkb9LP3","gpuType":"T4","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"},"widgets":{"application/vnd.jupyter.widget-state+json":{"086f5ed47ba94c0eadc86210ac8e3260":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_84409f35a2384f759f0097e1c7ad76c7","max":209,"min":0,"orientation":"horizontal","style":"IPY_MODEL_87d3246e6da9417ab3b77820175c1999","value":205}},"17abbf90314645a2b37255c6d8766105":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_75f5b637d77d4ba6af70ee3717a2814c","IPY_MODEL_086f5ed47ba94c0eadc86210ac8e3260","IPY_MODEL_a38cdf33185f41d08aee3083173fb6f0"],"layout":"IPY_MODEL_a116a4c0aa0244feba3e06de6f0d85a7"}},"1e195d2449294b4e89434797e1719f0f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bc5f3b7a6fe4424aacb748ce289a166":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75f5b637d77d4ba6af70ee3717a2814c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6bc5f3b7a6fe4424aacb748ce289a166","placeholder":"​","style":"IPY_MODEL_e50de81ddb4741c59aec1629e9a1ddc6","value":" 98%"}},"784cde4c71584ea78a97b6497e15c672":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84409f35a2384f759f0097e1c7ad76c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87d3246e6da9417ab3b77820175c1999":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a116a4c0aa0244feba3e06de6f0d85a7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a38cdf33185f41d08aee3083173fb6f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e195d2449294b4e89434797e1719f0f","placeholder":"​","style":"IPY_MODEL_784cde4c71584ea78a97b6497e15c672","value":" 205/209 [02:08&lt;00:02,  1.57it/s]"}},"e50de81ddb4741c59aec1629e9a1ddc6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
