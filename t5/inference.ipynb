{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/horovod/common/util.py:258: UserWarning: Framework pytorch installed with version 1.10.2+cu111 but found version 1.10.1+cu111.\n",
      "             This can result in unexpected behavior including runtime errors.\n",
      "             Reinstall Horovod using `pip install --no-cache-dir` to build with the new version.\n",
      "  warnings.warn(get_version_mismatch_message(name, version, installed_version))\n",
      "/usr/local/lib/python3.9/dist-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/usr/local/lib/python3.9/dist-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/usr/local/lib/python3.9/dist-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/usr/local/lib/python3.9/dist-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from model import T5ModelForPreTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "config = PeftConfig.from_pretrained(\"augustinLib/KET5-Prefix-Tuning-Lbox\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"KETI-AIR/ke-t5-large\", repetition_penalty=7.2)\n",
    "model = PeftModel.from_pretrained(model, \"augustinLib/KET5-Prefix-Tuning-Lbox\")\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"KETI-AIR/ke-t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 12,582,912 || all params: 795,601,920 || trainable%: 1.5815587775353785\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tokenizer.get_vocab()\n",
    "a[\".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda:0\")\n",
    "inputs = tokenizer(\n",
    "    \"누구든지 게임물의 이용을 통하여 획득한 유무형의 결과물을 환전 또는 환전 알선하거나 재매입을 업으로 하는 행위를 하여서는 아니 된다. 그럼에도 불구하고, 피고인은 2021. 3. 23. 21:20경 서울 중랑구 B에 있는 'C'에서, 손님으로 가장한 경찰관에게 현금 50,000원을 받고 ‘선파워 맞고’ 게임머니 5만 포인트를 충전하여 준 다음, 위 경찰관이 남긴 게임머니 17,000포인트를 현금 2만원으로 환전하여 주었다. 이로써 피고인은 게임물의 이용을 통하여 획득한 유무형의 결과물의 환전을 업으로 하였다.\",\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=512,\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[55912,  1352, 20213,  1170,    11, 11760, 26764, 24904, 18003, 18005,\n",
       "            11, 30723,   739, 30723, 24733,  1104,   997, 22662,    11,  7478,\n",
       "            45,   153,  8139,  5884,  3299,  1712,   304,     3,  6776,  2000,\n",
       "             4, 13920,    19,  9392,     3,    57,     3,   573,     3,   495,\n",
       "         33930,   508,   203, 50654,   384,     9,    53,    33,   497,    17,\n",
       "            37,     4, 11538,    45,   189,    50,  9115,   156,  4801, 43948,\n",
       "          2655,   580,    42,   270, 14207,  8029,    24,  1352, 17502,    77,\n",
       "            58, 15088,  8323,   479,  1955,   794,     4,  1338,  9115,    15,\n",
       "          8496,  1352, 17502,    44, 18982,  1096,    21,  4801,    51,  4061,\n",
       "         30723,   479, 10019,     3,  5324, 13920,    19,  1352, 20213,  1170,\n",
       "            11, 11760, 26764, 24904, 18003, 18005,     6, 30723,    11,  7478,\n",
       "            45,  6389,     3,     1,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0, 58172, 63998, 63998, 63998, 63998, 63998, 63998, 63998, 63998,\n",
      "         63998, 63998, 63998, 63998, 63998, 63998, 63998, 63998, 63998, 63998,\n",
      "         63998, 63998, 63998, 63998, 63998, 63998, 63998, 63998, 63998, 63998,\n",
      "         63998, 63998, 63998]], device='cuda:0')\n",
      "['활로를덟덟덟덟덟덟덟덟덟덟덟덟덟덟덟덟덟덟덟덟덟덟덟덟덟덟덟덟덟덟덟']\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    inputs = {k: v.to(\"cuda:0\") for k, v in inputs.items()}\n",
    "    outputs = model.generate(input_ids=inputs[\"input_ids\"], max_new_tokens=32,num_beams=4, temperature=1.5, top_k=10, top_p=0.9, length_penalty=0.65)\n",
    "    print(outputs)\n",
    "    print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
